name: Native Build - SageAttention Wheels (Fast CI)

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      torch_version:
        description: "PyTorch version"
        required: false
        default: "2.8.0"
      cuda_version:
        description: "CUDA version"
        required: false
        default: "12.9"
      python_version:
        description: "Python version"
        required: false
        default: "3.12"

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Job 1: Build Linux wheels natively (much faster than Docker)
  build-linux-wheels-native:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          # Linux builds - PyTorch 2.7 + CUDA 12.8 (matches docker-bake.hcl)
          - platform: linux
            torch_version: "2.7.0"
            cuda_index: "cu128"
            cuda_version: "12.8"
            cuda_version_full: "12.8.1"
            python_version: "3.12"
          # Linux builds - PyTorch 2.8 + CUDA 12.9 (matches docker-bake.hcl)
          - platform: linux
            torch_version: "2.8.0"
            cuda_index: "cu129"
            cuda_version: "12.9"
            cuda_version_full: "12.9.1"
            python_version: "3.12"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Free Disk Space (Aggressive)
        uses: jlumbroso/free-disk-space@main
        with:
          tool-cache: true
          android: true
          dotnet: true
          haskell: true
          large-packages: true
          docker-images: true
          swap-storage: true

      - name: Set up Python ${{ matrix.python_version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python_version }}

      - name: Install CUDA Toolkit
        run: |
          # Remove any existing broken CUDA installations
          sudo apt-get remove --purge -y cuda* nvidia* || true
          sudo apt-get autoremove -y
          
          # Add NVIDIA's official repository
          wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
          sudo dpkg -i cuda-keyring_1.0-1_all.deb
          sudo apt-get update
          
          # Install CUDA components based on matrix version
          CUDA_VERSION_MAJOR_MINOR="${{ matrix.cuda_version }}"
          CUDA_VERSION_DASHED=$(echo $CUDA_VERSION_MAJOR_MINOR | tr '.' '-')
          
          echo "Installing CUDA $CUDA_VERSION_MAJOR_MINOR components..."
          sudo apt-get install -y --no-install-recommends \
            cuda-compiler-${CUDA_VERSION_DASHED} \
            cuda-cudart-dev-${CUDA_VERSION_DASHED} \
            cuda-driver-dev-${CUDA_VERSION_DASHED} \
            cuda-nvcc-${CUDA_VERSION_DASHED} \
            libcublas-dev-${CUDA_VERSION_DASHED} \
            libcusparse-dev-${CUDA_VERSION_DASHED} \
            libcurand-dev-${CUDA_VERSION_DASHED}
            
          export CUDA_HOME=/usr/local/cuda-${CUDA_VERSION_MAJOR_MINOR}
          echo "CUDA_HOME=/usr/local/cuda-${CUDA_VERSION_MAJOR_MINOR}" >> $GITHUB_ENV
          echo "/usr/local/cuda-${CUDA_VERSION_MAJOR_MINOR}/bin" >> $GITHUB_PATH
          echo "LD_LIBRARY_PATH=/usr/local/cuda-${CUDA_VERSION_MAJOR_MINOR}/lib64:$LD_LIBRARY_PATH" >> $GITHUB_ENV
          sudo ln -sf /usr/local/cuda-${CUDA_VERSION_MAJOR_MINOR} /usr/local/cuda

      - name: Verify CUDA installation
        run: |
          echo "CUDA_HOME: $CUDA_HOME"
          echo "PATH: $PATH"
          which nvcc
          nvcc --version
          ls -la $CUDA_HOME/bin/
          echo "CUDA installation verified successfully"

      - name: Set up build environment
        run: |
          # Set environment variables for the build
          echo "TORCH_VERSION=${{ matrix.torch_version }}" >> $GITHUB_ENV
          echo "CUDA_VERSION=${{ matrix.cuda_version_full }}" >> $GITHUB_ENV
          echo "PYTHON_VERSION=${{ matrix.python_version }}" >> $GITHUB_ENV
          echo "TORCH_CUDA_ARCH_LIST=8.0;8.6;8.9;9.0;12.0" >> $GITHUB_ENV

      - name: Install PyTorch and dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel packaging
          
          # Install PyTorch with appropriate CUDA support
          pip install torch==${{ matrix.torch_version }} torchvision --index-url https://download.pytorch.org/whl/${{ matrix.cuda_index }}
          
          # Install build dependencies  
          pip install numpy packaging pybind11

      - name: Update PyTorch version in pyproject.toml
        run: python update_pyproject.py

      - name: Build SageAttention wheel
        run: |
          python setup.py bdist_wheel
          
      - name: Create build directory and move wheel
        run: |
          mkdir -p build
          # Clean build directory first to ensure only wheels
          rm -rf build/*
          # Move only wheel files
          mv dist/*.whl build/
          # Remove any non-wheel files that might have been created
          find build/ -type f ! -name "*.whl" -delete
          find build/ -type d -empty -delete
          echo "Final build directory contents:"
          ls -la build/

      - name: Test wheel installation
        run: |
          # Test in a separate virtual environment
          python -m venv test_env
          source test_env/bin/activate
          pip install build/*.whl
          python -c "import sageattention; print('SageAttention imported successfully')"
          deactivate

      - name: Upload wheel artifacts
        uses: actions/upload-artifact@v4
        with:
          name: sageattention-native-wheels-${{ matrix.platform }}-pytorch${{ matrix.torch_version }}-${{ matrix.cuda_index }}
          path: build/*.whl
          retention-days: 7

  # Job 2: Build Windows wheels natively (much faster than Docker)
  build-windows-wheels-native:
    runs-on: windows-2022
    strategy:
      matrix:
        include:
          # Windows builds - PyTorch 2.7 + CUDA 12.8 (matches docker-bake.hcl)
          - platform: windows
            torch_version: "2.7.0"
            cuda_index: "cu128"
            cuda_version: "12.8"
            cuda_version_full: "12.8.1"
            python_version: "3.12"
          # Windows builds - PyTorch 2.8 + CUDA 12.9 (matches docker-bake.hcl)
          - platform: windows
            torch_version: "2.8.0"
            cuda_index: "cu129"
            cuda_version: "12.9"
            cuda_version_full: "12.9.1"
            python_version: "3.12"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Free Disk Space (Windows)
        shell: powershell
        run: |
          # Remove .NET frameworks (keep Visual Studio for compilation)
          Write-Output "Removing .NET components..."
          Get-ChildItem -Path "C:\Program Files\dotnet" -ErrorAction SilentlyContinue | Remove-Item -Recurse -Force -ErrorAction SilentlyContinue
          Get-ChildItem -Path "C:\Program Files (x86)\dotnet" -ErrorAction SilentlyContinue | Remove-Item -Recurse -Force -ErrorAction SilentlyContinue
          
          # Clean tool cache
          Write-Output "Cleaning tool cache..."
          Get-ChildItem -Path "$env:AGENT_TOOLSDIRECTORY" -ErrorAction SilentlyContinue | Remove-Item -Recurse -Force -ErrorAction SilentlyContinue
          
          # Remove other large components but keep Visual Studio
          Write-Output "Removing Android SDK..."
          Get-ChildItem -Path "$env:ANDROID_HOME" -ErrorAction SilentlyContinue | Remove-Item -Recurse -Force -ErrorAction SilentlyContinue
          
          Write-Output "Cleaning temp directories..."
          Get-ChildItem -Path "$env:TEMP" -ErrorAction SilentlyContinue | Remove-Item -Recurse -Force -ErrorAction SilentlyContinue

      - name: Set up Python ${{ matrix.python_version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python_version }}

      - name: Install CUDA Toolkit (Windows)
        uses: Jimver/cuda-toolkit@v0.2.16
        with:
          cuda: '${{ matrix.cuda_version_full }}'
          method: 'network'
          sub-packages: '["nvcc", "cudart", "cublas", "cusparse", "curand"]'

      - name: Set up MSVC
        uses: ilammy/msvc-dev-cmd@v1
        with:
          arch: x64

      - name: Verify CUDA installation
        shell: powershell
        run: |
          Write-Output "CUDA_HOME: $env:CUDA_HOME"
          Write-Output "PATH: $env:PATH"
          try { 
            & nvcc --version 
            Write-Output "NVCC found and working"
          } catch { 
            Write-Output "NVCC not available, build may continue with CPU-only PyTorch"
          }
          if (Test-Path "$env:CUDA_HOME\bin") {
            Get-ChildItem -Path "$env:CUDA_HOME\bin" | Select-Object Name | Format-Table -AutoSize
          }

      - name: Set up build environment
        shell: powershell
        run: |
          # Set environment variables
          Write-Output "TORCH_VERSION=${{ matrix.torch_version }}" >> $env:GITHUB_ENV
          Write-Output "CUDA_VERSION=${{ matrix.cuda_version_full }}" >> $env:GITHUB_ENV
          Write-Output "PYTHON_VERSION=${{ matrix.python_version }}" >> $env:GITHUB_ENV
          Write-Output "TORCH_CUDA_ARCH_LIST=8.0;8.6;8.9;9.0;12.0" >> $env:GITHUB_ENV

      - name: Install PyTorch and dependencies
        shell: powershell
        run: |
          python -m pip install --upgrade pip setuptools wheel packaging
          
          # Install PyTorch with appropriate CUDA support
          pip install torch=="${{ matrix.torch_version }}" torchvision --index-url https://download.pytorch.org/whl/${{ matrix.cuda_index }}
          
          # Install build dependencies
          pip install numpy packaging pybind11

      - name: Update PyTorch version in pyproject.toml
        run: python update_pyproject.py

      - name: Build SageAttention wheel
        shell: powershell
        run: |
          python setup.py bdist_wheel

      - name: Create build directory and move wheel
        shell: powershell
        run: |
          New-Item -ItemType Directory -Force -Path build
          # Clean build directory first to ensure only wheels
          Remove-Item build\* -Recurse -Force -ErrorAction SilentlyContinue
          # Move only wheel files
          Move-Item dist\*.whl build\
          # Remove any non-wheel files that might have been created
          Get-ChildItem build\ | Where-Object { $_.Extension -ne ".whl" } | Remove-Item -Recurse -Force
          Write-Output "Final build directory contents:"
          Get-ChildItem build\

      - name: Test wheel installation
        shell: powershell
        run: |
          # Test in a separate virtual environment
          python -m venv test_env
          & "test_env\Scripts\Activate.ps1"
          pip install build\*.whl
          python -c "import sageattention; print('SageAttention imported successfully')"

      - name: Upload wheel artifacts
        uses: actions/upload-artifact@v4
        with:
          name: sageattention-native-wheels-${{ matrix.platform }}-pytorch${{ matrix.torch_version }}-${{ matrix.cuda_index }}
          path: build/*.whl
          retention-days: 7

  # Job 3: Publish wheels to GitHub Packages
  publish-wheels-native:
    needs: [build-linux-wheels-native, build-windows-wheels-native]
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request' && github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all wheel artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: sageattention-native-wheels-*
          merge-multiple: true
          path: wheels/

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install twine
        run: pip install twine

      - name: List all wheels
        run: |
          echo "=== Native Build Results ==="
          find wheels/ -name "*.whl" -type f | sort
          echo ""
          echo "Wheel sizes:"
          find wheels/ -name "*.whl" -type f -exec ls -lh {} \;

      - name: Create PyPI configuration
        run: |
          cat > ~/.pypirc << EOF
          [distutils]
          index-servers =
              github
          
          [github]
          repository = https://github.com/${{ github.repository }}/packages/pypi
          username = ${{ github.actor }}
          password = ${{ secrets.GITHUB_TOKEN }}
          EOF

      - name: Publish to GitHub Packages
        run: |
          # Find all wheel files
          find wheels/ -name "*.whl" -type f | while read wheel; do
            echo "Uploading $wheel to GitHub Packages..."
            twine upload --repository github "$wheel"
          done
